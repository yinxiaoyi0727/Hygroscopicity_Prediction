{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from tabpfn import TabPFNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(best_model, X, y_true):\n",
    "    y_pred = best_model.predict(X)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    performance = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "    }\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 1\n",
      "performance_train=\n",
      "{'MAE': 0.1040024861783403, 'MSE': 0.03206843395826335, 'R2': 0.9501124947137605}\n",
      "performance_test=\n",
      "{'MAE': 0.26072009487516445, 'MSE': 0.13798345807338214, 'R2': 0.5858354892618254}\n",
      "\n",
      "Round 2\n",
      "performance_train=\n",
      "{'MAE': 0.10059049487236027, 'MSE': 0.02954020298081067, 'R2': 0.9522654632609906}\n",
      "performance_test=\n",
      "{'MAE': 0.23824110182346364, 'MSE': 0.11779884192666747, 'R2': 0.8043972365579426}\n",
      "\n",
      "Round 3\n",
      "performance_train=\n",
      "{'MAE': 0.10612567303448915, 'MSE': 0.0338230116990043, 'R2': 0.94469213421151}\n",
      "performance_test=\n",
      "{'MAE': 0.2669140505068853, 'MSE': 0.12046245739595314, 'R2': 0.8149099177320812}\n",
      "\n",
      "Round 4\n",
      "performance_train=\n",
      "{'MAE': 0.11253399538881785, 'MSE': 0.03582008675422139, 'R2': 0.9423632324478263}\n",
      "performance_test=\n",
      "{'MAE': 0.24037653430301018, 'MSE': 0.15011851351123026, 'R2': 0.7345641559892564}\n",
      "\n",
      "Round 5\n",
      "performance_train=\n",
      "{'MAE': 0.10657013822080434, 'MSE': 0.03288953437313876, 'R2': 0.9481588084219555}\n",
      "performance_test=\n",
      "{'MAE': 0.22140983493470848, 'MSE': 0.10709236239847861, 'R2': 0.7695027167507964}\n",
      "\n",
      "Round 6\n",
      "performance_train=\n",
      "{'MAE': 0.10308070414500276, 'MSE': 0.030995856855304465, 'R2': 0.9492163165067495}\n",
      "performance_test=\n",
      "{'MAE': 0.23979337084966623, 'MSE': 0.13216790544852675, 'R2': 0.8037224344394392}\n",
      "\n",
      "Round 7\n",
      "performance_train=\n",
      "{'MAE': 0.10661624747587287, 'MSE': 0.0338114927042341, 'R2': 0.9440837599747316}\n",
      "performance_test=\n",
      "{'MAE': 0.22201217084313485, 'MSE': 0.0948350020654955, 'R2': 0.8704054506506784}\n",
      "\n",
      "Round 8\n",
      "performance_train=\n",
      "{'MAE': 0.1077649888844449, 'MSE': 0.033892532741734024, 'R2': 0.9417567184639185}\n",
      "performance_test=\n",
      "{'MAE': 0.2263065097111533, 'MSE': 0.09882216063412069, 'R2': 0.8929909834538043}\n",
      "\n",
      "Round 9\n",
      "performance_train=\n",
      "{'MAE': 0.11220482102099585, 'MSE': 0.03581456984391239, 'R2': 0.943115016258948}\n",
      "performance_test=\n",
      "{'MAE': 0.23123075136783583, 'MSE': 0.12791673146316446, 'R2': 0.7468513611444834}\n",
      "\n",
      "Round 10\n",
      "performance_train=\n",
      "{'MAE': 0.11002336345508534, 'MSE': 0.03611616872674441, 'R2': 0.9413682218375035}\n",
      "performance_test=\n",
      "{'MAE': 0.19821597801483312, 'MSE': 0.0729010488095601, 'R2': 0.8832147742178685}\n",
      "\n",
      "Average Train Performance:\n",
      "MAE  : 0.107 ± 0.004\n",
      "MSE  : 0.033 ± 0.002\n",
      "R2   : 0.946 ± 0.004\n",
      "\n",
      "Average Test Performance:\n",
      "MAE  : 0.235 ± 0.020\n",
      "MSE  : 0.116 ± 0.023\n",
      "R2   : 0.791 ± 0.091\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data03.csv\")\n",
    "X = data.iloc[:, 2:]\n",
    "y = data['value']\n",
    "group = data['group']\n",
    "\n",
    "# Initialize lists to store performance metrics\n",
    "train_performance = []\n",
    "val_performance = []\n",
    "test_performance = []\n",
    "\n",
    "all_test_preds = []\n",
    "\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "round_id = 1  # 初始化轮次编号\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in gkf.split(X, y, group):\n",
    "    \n",
    "    print(f\"\\nRound {round_id}\")  # 打印当前轮次\n",
    "    round_id += 1\n",
    "    \n",
    "    train_data = data.iloc[train_index]\n",
    "    test_data = data.iloc[test_index]\n",
    "\n",
    "    X_train = train_data.iloc[:, 2:]\n",
    "    y_train = train_data['value']\n",
    "    group_train = train_data['group']\n",
    "\n",
    "    X_test = test_data.iloc[:, 2:]\n",
    "    y_test = test_data['value']\n",
    "    group_test = test_data['group']\n",
    "\n",
    "    model = TabPFNRegressor(device=\"cuda\")   \n",
    "\n",
    "    # Fit the model\n",
    "    # Note: TabPFNRegressor does not require hyperparameter tuning like LGBMRegressor\n",
    "    model_train = model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate performance on training and test sets\n",
    "    performance_train = evaluate_performance(model_train, X_train, y_train)\n",
    "    performance_test = evaluate_performance(model_train, X_test, y_test)\n",
    "\n",
    "    # Store performance metrics\n",
    "    train_performance.append(performance_train)\n",
    "    test_performance.append(performance_test)\n",
    "    \n",
    "    print(\"performance_train=\")\n",
    "    print(performance_train)\n",
    "    print(\"performance_test=\")\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    fold_result = pd.DataFrame({\n",
    "        'true_value': y_test.values,\n",
    "        'predicted_value': y_pred_test,\n",
    "        'group': test_data['group'].values,\n",
    "        'time': test_data['Time'].values\n",
    "    })\n",
    "    all_test_preds.append(fold_result)\n",
    "\n",
    "# Combine and save results\n",
    "final_result = pd.concat(all_test_preds, ignore_index=True)\n",
    "final_result.to_csv(\"test_result_03.csv\", index=False)\n",
    "\n",
    "\n",
    "# Calculate average performance metrics\n",
    "avg_train_performance = pd.DataFrame(train_performance).mean()\n",
    "avg_test_performance = pd.DataFrame(test_performance).mean()\n",
    "std_train_performance = pd.DataFrame(train_performance).std()\n",
    "std_test_performance = pd.DataFrame(test_performance).std()\n",
    "\n",
    "# Print average performance metrics\n",
    "print(\"\\nAverage Train Performance:\")\n",
    "for metric in avg_train_performance.index:\n",
    "    avg = avg_train_performance[metric]\n",
    "    std = std_train_performance[metric]\n",
    "    print(f\"{metric:<5}: {avg:.3f} ± {std:.3f}\")\n",
    "\n",
    "print(\"\\nAverage Test Performance:\")\n",
    "for metric in avg_test_performance.index:\n",
    "    avg = avg_test_performance[metric]\n",
    "    std = std_test_performance[metric]\n",
    "    print(f\"{metric:<5}: {avg:.3f} ± {std:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
