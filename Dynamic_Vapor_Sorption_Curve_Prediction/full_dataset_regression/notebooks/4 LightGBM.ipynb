{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(best_model, X, y_true):\n",
    "    y_pred = best_model.predict(X)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    performance = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "    }\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New round 1\n",
      "performance_train=\n",
      "{'MAE': 0.24889451565058204, 'MSE': 0.1453856132903259, 'R2': 0.8235737075150815}\n",
      "performance_val=\n",
      "MAE    0.310775\n",
      "MSE    0.234675\n",
      "R2     0.709655\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.29458858550028966, 'MSE': 0.21771182257483013, 'R2': 0.650102205361013}\n",
      "\n",
      "New round 2\n",
      "performance_train=\n",
      "{'MAE': 0.2043923497496706, 'MSE': 0.10039137529135989, 'R2': 0.8726202376752739}\n",
      "performance_val=\n",
      "MAE    0.317609\n",
      "MSE    0.234941\n",
      "R2     0.692739\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.29653679682538386, 'MSE': 0.1943723620715951, 'R2': 0.7958839629811747}\n",
      "\n",
      "New round 3\n",
      "performance_train=\n",
      "{'MAE': 0.22978962774085987, 'MSE': 0.12806964644891392, 'R2': 0.8378434926147205}\n",
      "performance_val=\n",
      "MAE    0.311682\n",
      "MSE    0.227705\n",
      "R2     0.710291\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.3442581232028365, 'MSE': 0.22701104865667315, 'R2': 0.7572706837009966}\n",
      "\n",
      "New round 4\n",
      "performance_train=\n",
      "{'MAE': 0.2598226481717492, 'MSE': 0.15572896307988424, 'R2': 0.8106524396613723}\n",
      "performance_val=\n",
      "MAE    0.309786\n",
      "MSE    0.232348\n",
      "R2     0.717436\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.29764672505429984, 'MSE': 0.23250383196129457, 'R2': 0.6372333519735556}\n",
      "\n",
      "New round 5\n",
      "performance_train=\n",
      "{'MAE': 0.17487957568150708, 'MSE': 0.07248622134571023, 'R2': 0.9110360262312572}\n",
      "performance_val=\n",
      "MAE    0.299934\n",
      "MSE    0.214889\n",
      "R2     0.729019\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.3433769731925746, 'MSE': 0.3047489123054644, 'R2': 0.5826047797120548}\n",
      "\n",
      "New round 6\n",
      "performance_train=\n",
      "{'MAE': 0.1656503982724158, 'MSE': 0.06801954578699841, 'R2': 0.9138653027725467}\n",
      "performance_val=\n",
      "MAE    0.313720\n",
      "MSE    0.231342\n",
      "R2     0.703920\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.33156189824333837, 'MSE': 0.25843634905505, 'R2': 0.7053954836167591}\n",
      "\n",
      "New round 7\n",
      "performance_train=\n",
      "{'MAE': 0.24905060145280342, 'MSE': 0.147107547996477, 'R2': 0.8122215253425988}\n",
      "performance_val=\n",
      "MAE    0.313235\n",
      "MSE    0.236485\n",
      "R2     0.688014\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.32022373413187055, 'MSE': 0.2159238205847546, 'R2': 0.7855194200591556}\n",
      "\n",
      "New round 8\n",
      "performance_train=\n",
      "{'MAE': 0.21258915465099648, 'MSE': 0.10503919789454237, 'R2': 0.871323408079075}\n",
      "performance_val=\n",
      "MAE    0.305944\n",
      "MSE    0.226439\n",
      "R2     0.710610\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.3250972390571331, 'MSE': 0.22425349147193718, 'R2': 0.6861186291264856}\n",
      "\n",
      "New round 9\n",
      "performance_train=\n",
      "{'MAE': 0.23927451573195407, 'MSE': 0.1349360680648732, 'R2': 0.8345857820148159}\n",
      "performance_val=\n",
      "MAE    0.312811\n",
      "MSE    0.230906\n",
      "R2     0.712997\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.3120922301604233, 'MSE': 0.2555455081281165, 'R2': 0.6405399842268712}\n",
      "\n",
      "New round 10\n",
      "performance_train=\n",
      "{'MAE': 0.25422199050952343, 'MSE': 0.15358894839309004, 'R2': 0.8117792476047279}\n",
      "performance_val=\n",
      "MAE    0.317089\n",
      "MSE    0.238180\n",
      "R2     0.702392\n",
      "dtype: float64\n",
      "performance_test=\n",
      "{'MAE': 0.259181044117105, 'MSE': 0.15848559084607342, 'R2': 0.7669107914885928}\n",
      "\n",
      "Average Train Performance:MAE    0.223857\n",
      "MSE    0.121075\n",
      "R2     0.849950\n",
      "dtype: float64+/-MAE    0.033404\n",
      "MSE    0.032708\n",
      "R2     0.039848\n",
      "dtype: float64\n",
      "\n",
      "Average Validation Performance: MAE    0.311259\n",
      "MSE    0.230791\n",
      "R2     0.707707\n",
      "dtype: float64 +/- MAE    0.005226\n",
      "MSE    0.006695\n",
      "R2     0.011786\n",
      "dtype: float64\n",
      "\n",
      "Average Test Performance: MAE    0.312456\n",
      "MSE    0.228899\n",
      "R2     0.700758\n",
      "dtype: float64 +/- MAE    0.026211\n",
      "MSE    0.039183\n",
      "R2     0.073202\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data02.csv\")\n",
    "X = data.iloc[:, 2:]\n",
    "y = data['value']\n",
    "group = data['group']\n",
    "\n",
    "# Initialize lists to store performance metrics\n",
    "train_performance = []\n",
    "val_performance = []\n",
    "test_performance = []\n",
    "\n",
    "all_test_preds = []\n",
    "\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "\n",
    "val_test_diff_list = []\n",
    "param_list = []\n",
    "\n",
    "round_id = 1\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in gkf.split(X, y, group):\n",
    "    print(f\"\\nNew round {round_id}\")\n",
    "    round_id += 1\n",
    "    \n",
    "    remain_data = data.iloc[train_index]\n",
    "    test_data = data.iloc[test_index]\n",
    "\n",
    "    X_remain=remain_data.iloc[:, 2:]\n",
    "    y_remain=remain_data['value']\n",
    "    group_remain=remain_data['group']\n",
    "\n",
    "    X_test=test_data.iloc[:, 2:]\n",
    "    y_test=test_data['value']\n",
    "    group_test=test_data['group']\n",
    "\n",
    "    p_grid = {'n_estimators': Integer(100, 500), \n",
    "                    'learning_rate': Real(0.001, 0.1), \n",
    "                    'num_leaves': Integer(2, 50), \n",
    "                    'subsample': Real(0.5, 1.0), \n",
    "                    'subsample_freq': Integer(1, 5),  \n",
    "                    'colsample_bytree': Real(0.1, 1.0),  \n",
    "                    'colsample_bynode': Real(0.1, 1.0),  \n",
    "                    'reg_alpha': Real(0.0, 5.0),  \n",
    "                    'reg_lambda': Real(0.0, 10.0),\n",
    "                    'max_depth': Integer(3, 10)}\n",
    "    \n",
    "    # configure the cross-validation procedure - inner loop (validation set/HP optimization)\n",
    "    cv_inner = GroupKFold(n_splits=10)  \n",
    "\n",
    "    model = LGBMRegressor(random_state=42, n_jobs=-1, verbose = -1)\n",
    "    \n",
    "    # define search space\n",
    "    search = BayesSearchCV(model, p_grid, n_iter=100, verbose=0, scoring='r2', cv=cv_inner,  n_jobs= -1, refit=True) # should be 100\n",
    "    \n",
    "    # execute search\n",
    "    result = search.fit(X_remain, y_remain, groups=group_remain)\n",
    "        \n",
    "    # get the best performing model fit on the whole training set\n",
    "    # 十次交叉验证找出最优参数\n",
    "    best_model = result.best_estimator_           \n",
    "\n",
    "    # Fit the best model on the entire training set\n",
    "    # 在整个训练集上拟合最优模型best_model_remain，得到训练集和测试集的性能\n",
    "    best_model_remain=best_model.fit(X_remain, y_remain)\n",
    "    performance_train = evaluate_performance(best_model_remain, X_remain, y_remain)\n",
    "    performance_test = evaluate_performance(best_model_remain, X_test, y_test)\n",
    "\n",
    "    # 添加 test 预测结果\n",
    "    y_test_pred = best_model_remain.predict(X_test)\n",
    "    test_pred_df = pd.DataFrame({\n",
    "        'true_value': y_test.values,\n",
    "        'predicted_value': y_test_pred,\n",
    "        'group': test_data['group'].values,  # 可选：保留 group 信息\n",
    "        'time': test_data['Time'].values  # 可选：保留时间信息\n",
    "    })\n",
    "    all_test_preds.append(test_pred_df)\n",
    "        \n",
    "    allfold_performance_val = []\n",
    "    \n",
    "    # 记录验证集结果，在内层X_remain交叉验证中计算验证集性能\n",
    "    for train_idx, valid_idx in cv_inner.split(X_remain, y_remain, groups=group_remain):\n",
    "        X_train = X_remain.iloc[train_idx]\n",
    "        y_train = y_remain.iloc[train_idx]\n",
    "        X_val = X_remain.iloc[valid_idx]\n",
    "        y_val = y_remain.iloc[valid_idx]\n",
    "\n",
    "        model_train = best_model.fit(X_train, y_train)\n",
    "        \n",
    "        fold_performance_val = evaluate_performance(model_train, X_val, y_val)\n",
    "\n",
    "        allfold_performance_val.append(fold_performance_val)\n",
    "\n",
    "        performance_val = pd.DataFrame(allfold_performance_val).mean()\n",
    "\n",
    "    # 存储性能\n",
    "    train_performance.append(performance_train)\n",
    "    val_performance.append(performance_val)\n",
    "    test_performance.append(performance_test)\n",
    "    \n",
    "    print(\"performance_train=\")\n",
    "    print(performance_train)\n",
    "    print(\"performance_val=\")\n",
    "    print(performance_val)\n",
    "    print(\"performance_test=\")\n",
    "    print(performance_test)\n",
    "\n",
    "    val_r2 = performance_val['R2']\n",
    "    test_r2 = performance_test['R2']\n",
    "    val_test_diff = abs(val_r2 - test_r2)\n",
    "    val_test_diff_list.append(val_test_diff)\n",
    "    param_list.append(result.best_params_)\n",
    "\n",
    "\n",
    "# 汇总10折预测结果\n",
    "final_test_result = pd.concat(all_test_preds, ignore_index=True)\n",
    "final_test_result.to_csv('test_results_LGBM.csv', index=False)\n",
    "\n",
    "# Calculate average performance metrics\n",
    "avg_train_performance = pd.DataFrame(train_performance).mean()\n",
    "avg_val_performance = pd.DataFrame(val_performance).mean()\n",
    "avg_test_performance = pd.DataFrame(test_performance).mean()\n",
    "std_train_performance = pd.DataFrame(train_performance).std()\n",
    "std_val_performance = pd.DataFrame(val_performance).std()\n",
    "std_test_performance = pd.DataFrame(test_performance).std()\n",
    "\n",
    "# Print av erage performance metrics\n",
    "print(\"\\n\" +\"Average Train Performance:\" + str(avg_train_performance) + \"+/-\" + str(std_train_performance))\n",
    "print(\"\\n\" +\"Average Validation Performance:\", avg_val_performance, \"+/-\", std_val_performance)\n",
    "print(\"\\n\" +\"Average Test Performance:\", avg_test_performance, \"+/-\", std_test_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建性能汇总 DataFrame（包含最优参数）\n",
    "performance_by_fold = pd.DataFrame({\n",
    "    'Fold': list(range(1, len(train_performance) + 1)),\n",
    "    'Train_R2': [p['R2'] for p in train_performance],\n",
    "    'Val_R2': [p['R2'] for p in val_performance],\n",
    "    'Test_R2': [p['R2'] for p in test_performance],\n",
    "    'Train_MAE': [p['MAE'] for p in train_performance],\n",
    "    'Val_MAE': [p['MAE'] for p in val_performance],\n",
    "    'Test_MAE': [p['MAE'] for p in test_performance],\n",
    "    'Train_MSE': [p['MSE'] for p in train_performance],\n",
    "    'Val_MSE': [p['MSE'] for p in val_performance],\n",
    "    'Test_MSE': [p['MSE'] for p in test_performance],\n",
    "    'Val_Test_R2_Diff': val_test_diff_list,\n",
    "    'Best_Params': param_list\n",
    "})\n",
    "\n",
    "# 保存为 CSV\n",
    "performance_by_fold.to_csv(\"LGBM_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 最优模型已保存：第 6 折参数（val-test最接近）用于全数据训练\n"
     ]
    }
   ],
   "source": [
    "# 找到 val-test 差值最小的一折\n",
    "best_param_idx = int(np.argmin(val_test_diff_list))\n",
    "best_params = param_list[best_param_idx]\n",
    "\n",
    "# 全部数据重新训练最终模型\n",
    "final_model = LGBMRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# 保存模型为 pickle\n",
    "import pickle\n",
    "with open(\"LGBM_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "print(f\"\\n✅ 最优模型已保存：第 {best_param_idx + 1} 折参数（val-test最接近）用于全数据训练\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
